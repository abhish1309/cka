~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					Containers-Docker
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> service docker status			### to check to status of docker engine/docker daemon

> sudo service docker start			### after installation of docker, start the docker

> sudo service docker enable			### to start docker at boot

~~~~~~~~~~~~~~~~~
	Container:-
~~~~~~~~~~~~~~~~~
> docker info			### to check if docker is installed or not, and its information if installed

> docker run nginx		### to run container image

> docker ps			### to check containers running

> docker rm <container id/container name>			### to remove container

> docker ps -a -q			### to get only container ids in output

> docker rm $(docker ps -a -q)			### to delete all containers

> docker rm `sudo docker ps -a -q`			### to delete all containers

~~~~~~~~~~~~~~
	Images:- 
~~~~~~~~~~~~~~
> docker images			### to check docker images available

> docker images -q			### to get only docker images id

> docker images | grep none | awk '{print $3}' | xargs docker rmi			### to delete none images.

> docker search < application name >			### to search application images available in docker hub

> docker pull <application name>			### to pull application images without running container

> docker rmi <image id/ image name>			### to remove images

> docker rmi $(docker images -q)			### to delete all images

> docker rmi `docker images -q`			### to delete all images



~~~~~~~~~~~~~~~~~~~~
	Build images:-
~~~~~~~~~~~~~~~~~~~~
> docker commit <running dockercontainerID name> < new image name>			### to create new image from current running docker
> docker commit 4aab3ce3cb76 jamtur01/apache2:webserver			### to save the containers changes for future use.

> docker build . -t myuser/image2			### to build from current location "Dockerfile" and tag the image

> docker build . -f Dockerfile2 -t myuser/image2	// to build from "Dockerfile2" (is the name of Dockerfile),tag to upload to Docker hub

> docker push x/y:z

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					PODs
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
kubectl run mypod11 --image=nginx --dry-run=client		### test the run virtually without actualy creating it, tests if the pod gets creates or fails (dry run)

kubectl run mypod12 --image=nginx --dry-run=client -o yaml		### display the file generated by cmd used  // generate & display POD manifest Yaml file (-o yaml). Dont create it(--dry-run)

kubectl run mypod13 --image=nginx --dry-run=client -o yaml > pod.yml		### generate a yaml file (pod.yaml) directly and then create pod using the file pod.yaml

kubectl run mypod14 --image=nginx --port=8080		### only pod definition file is created and container port is opened //create a pod "custom-mypod" using the nginx image and expose it on container port 8080
 
kubectl run mypod15 --image=nginx:alpine --port=80 --expose		### service & pod is created // Create a pod called httpd using the image httpd:alpine in the default namespace. Next, create a service of type ClusterIP by the same name (httpd). The target port for the service should be 80

k kubectl run mypod16 --image=nginx:alpine --port=80 --expose --dry-run=client -o yaml > pod-svc.yml		### pod & svc definition is created in a single file // can create pod & svc from the file 

kubectl run mypod17 --image=nginx --env="environment=production" --env="department=finance"		### assign environment variable while creating pod

kubectl run mypod18 --image=nginx --labels="app=myapp,tier=frontend"		### assign labels while creating pod

kubectl run mypod18 --image=nginx -l app=myapp,tier=frontend		### assign labels while creating pod

kubectl run mypod19 --image=nginx <arg1> <arg2> <argN>		### pass the argument by keeping the default command in container image.

kubectl run mypod20 --image=nginx --command -- <cmd> <arg1> <argN>		### pass the command and argument, overriding the container image command.

# kubectl run mypod21 --image=nginx --expose=false		### if true, service is created for the containers which are run

# hikubectl run mypod22 --image=nginx --serviceaccount=''		### service account to set in the pod spec. this may depricate in future.

# kubectl run mypod23 --image=nginx --annotations=[]		### annotations to apply to the pod.

kubectl run mypod24 --image=busybox -it --restart=Never --rm		### one time use pod/container. pod do not restarts and gets deleted when we exit shell/ or when work is done.

# kubectl run mypod25 --image=busybox -it --restart=Never --rm -- wget -O- 10.1.1.131:80		### it runs, execute the output, exits and pod is deleted.(ping and displays the output, gets deleted.)

# kubectl run mypod26 --image=busybox -it --restart=Never --rm -- sh -c 'wget -O- 10.1.1.131:80'		### passing command inside the container

kubectl create -f pod-definition.yml		### pod-definition.yml file which has information to create a pod.


kubectl get pods	### check pods created

kubectl get pods -o wide	### to get the ips of pod and other extra details

kubectl -n kube-system get pods		### get pods from namespace kube-system

kubectl get pods -A		### displays all pods including kube-system

Kubectl get pods,svc		### get list of pods and services

kubectl get all		### get list of all objects. Deployment, replicaset, services, pods

kubectl get pods --show-labels		### show pods with labels 

kubectl get pods -l purpose=demonstrate-envars		### get pods with the help of labels; purpose=demonstrate-envars 

kubectl get pods --label-columns=app		### to print the label values as a columns 

kubectl get pods --all-namespaces		### get pods from all namespaces

kubectl get pods --selector='app=demo2'		### 

kubectl get pods --field-selector=status.phase=Running		### Get all running pods in the namespace

kubectl get pod mypod -o yaml > nginx01.yaml		### to get the yaml definition file of currently running pod.

kubectl get pod mypod -o jsonpath='{.status.podIP}'		### to get the ip of the pod

kubectl get pod -o jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.spec.containers[*].image}{"\n"}{end}'	### get pod name & images list of all pods

kubectl get pod -o custom-columns='POD_NAME:.metadata.name,IMAGE:.spec.containers[*].image'		### print in columns, with headers

kubectl get pod -o custom-columns='POD_NAME:.metadata.name,IMAGE:.spec.containers[*].image' --no-headers		### print in columns, without  headers


kubectl describe pod mypod	### to inspect pod

kubectl edit pod mypod		### to edit/update the configuration of the running pod 'redis'


kubectl delete pod mypod	### to delete a pod "mypod"

kubectl delete pod mypod --force --grace-period=0		## delete the pod without wasting time

kubectl delete pod --selector="app=demo"		### delete pod using selector

kubectl delete pod -l app=label		### delete the pod using labels

kubectl delete -f pod.yaml		### all the resources in the file present in cluster will be deleted.

kubectl -n default delete pods --field-selector=status.phase=Failed		### To delete pods in Failed state in namespace default


kubectl label pod mypod app=demo	### to label existing pod

kubectl label pod mypod app=demo2 -overwrite	### if label is already existing and you need to edit value, then use -overwrite

kubectl label pod mypod app-		### to remove the label, use key and - sign at the end of it.


kubectl annotate po mypod1 description='my description'		### to add annotations for pod

kubectl annotate po mypod1 nginx2 nginx3 description='my description'	 ### to add annotations for multiple pods.


kubectl logs mypod		### to check logs of pods/containers

kubectl logs -f mypod		### to tail the logs

kubectl logs -f podname -c containername	### if we want a logs of specific container inside the pod

kubectl logs mypod -p		### logs of previously running pod


kubectl exec -it $POD_NAME -- bash		### to start a bash session in pods container ### sh, bash, /bin/sh, /bin/bash

kubectl exec mypod1 -- date		### to execute a command in a pod

kubectl exec mypod -c nginx-container -- date	### to execute command in container "nginx-container" of pod "mypod"

		
kubectl explain pods			### different attributes of pods.

kubectl explain pods.spec.containers		### to make the changes,


kubectl port-forward pod mypod	8888:5000	### listen on port 8888(local port) locally, forwarding to 5000(container port) in the pod. ### to check,test application locally. ## http://localhost:xxxx

kubectl set image pod mypod nginxcontainer=nginx:1.7.1		### kubetl set image POD/POD_NAME container_name=image:tag ### change the image on the fly.


ls

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					ReplicationController
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
kubectl create -f rc.yml	### create replication controller

kubectl get replicationcontroller	### check no of replication controller

kubectl get rc



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					Replicaset
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
kubectl create -f replicaset-definition.yml		### create replication set

kubectl get replicaset		### check replicationset

kubectl edit rs new-replica-set		### edit virtually.

kubectle replace -f replicaset-definition.yml		### first edit "replicas" property in *.yml file to scale replication set

kubectl delete replicaset myapp-replicaset		### delete replicaset

kubectl scale replicaset new-replica-set --replicas=2		### scale replicaset "new-replica-set" without updating data in file

## kubectl scale --replicas=6 -f replicaset-definintion.yml		### scale replicas by updating file & may need to apply to update



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					Deployment
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

kubectl create deployment mydeploy01 --image=nginx 		### Create a deployment without yaml file

kubectl create deployment mydeploy02 --image=nginx  --dry-run=client -o yaml		### creates deployment and displays Deployment in YAML format (-o yaml). Don't create it(--dry-run)

kubectl create deployment mydeploy03 --image=nginx --dry-run=client -o yaml > nginx-deployment.yaml		### Generate and save Deployment YAML file (-o yaml). Don't create it(--dry-run) , save to nginx-deployment.yaml

kubectl create deployment mydeploy04 --image=nginx --replicas=4 	### create Deployment with 4 Replicas and records it

kubectl create deployment mydeploy05 --image=nginx --replicas=3 --port=80 --dry-run=client -o yaml > deployment.yaml

kubectl create -f nginx-deployment.yml		### create deployment set from existing file "nginx-deployment.yml"

kubectl create -f mydeploy06.yaml --record		## record while creating


kubectl get deployments		### to check deployments
kubectl get replicaset		### to check replicaset created by deployment
kubectl get pods	### to check pods created by deployment

kubectl get all		### to check all that has been created by deployments in one output 


kubectl describe deployments.apps mydeploy03 		###  to describe the deployment

kubectl edit deployment mydeploy02 --record					## record after edit


kubectl scale deployment mydeploy01 --replicas=3 		### scale deployment, replicaset updated without updating file

kubectl expose deployment mydeploy01 --port 80	### to expose port 

kubectl set image deployment mydeploy02 nginxcontainer=nginx:1.17 --record		## record with imperative command


kubectl rollout status deployment mydeploy02		## to check rollout status

kubectl rollout history deploy mydeploy02		## to check history of rollout

kubectl rollout history deploy mydeploy02 --revision=2		## to check history for specific revision

kubectl rollout undo deploy mydeploy02				## undo one step back

kubectl rollout undo deploy mydeploy03 --to-revision=1		## undo to specific revision

kubectl rollout pause deploy mydeploy02			## pause while rolling

kubectl rollout resume deploy mydeploy02		## resume rolling


kubectl autoscale deployment mynginx --min=5 --max=10 --cpu-percent=80		## autosclling application

kubectl get hpa mynginx

kubectl delete hpd mynginx

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					Jobs
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

kubectl create job math-add-job --image=ubuntu -- expr 3 + 2

kubectl get jobs

kubectl logs job math-add-job-* 

kubectl delete job match-add-job-*


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					CronJobs
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

kubectl create cronjob busybox --image=busybox \
--schedule="*/1 * * * *" \
-- bin/sh -c 'date; echo Hello from the kubernetes cluster'



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					Namespace
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
kubectl create namespace dev		### create a namespace "dev"

kubectl get namespaces		### to check the existing namespaces
kubectl get ns

kubectl get ns --no-headers | wc -l		### check counts of namespace present

kubectl get pods --namespace=kube-system		### geting pods info from kube-system namespace

kubectl get pod	-n kube-system		### short method to access from required namespaces

kubectl -n kube-system get svc		### get services from namespace "kube-system"

kubectl -n kube-system get deployment 

kubectl get pods --all-namespaces	### it will list all pods present in all namespaces.

kubectl config set-context $(kubectl config current-context) --namespace=dev		### permenently switch to other namepace "dev". if we use get cmd for pods,deployment it will show details present in "dev" namespace only.



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					Services 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

kubectl create service clusterip mynginx-service --tcp=80:80 --dry-run=client -o yaml > nginx-service.yaml		## need to change the selector of service which matches deployment or pods/labels. to map service to deployment or pods.

kubectl create service nodeport mynginx-servie02 --tcp=80:80 --node-port=30080		## need to change selector,create a nodeport service. If you dont define nodeport, then kubernetes will assign any available port.

kubectl create service loadbalacer my-lbs --tcp=5678:8080				## need to change selector,create a loadbalancer

kubectl create -f svc.yaml	### to create a service using yaml file


kubectl run mypod02 --image=nginx --port=80 --expose		### create a pod and service at the same time. it can only be used to expose pod.

kubectl expose pod mypod01 --name redis-service --type=ClusterIP --port=6379  	### no need to change selector; pod must present to expose ##create as service redis-service to expose the redis application with the cluster on port 6379

kubectl expose deployment my-deployment02 --name=nginx-service --type=ClusterIP --port=80 --target-port=80		## expose with cluster IP

kubectl expose deployment my-deployment01 --name=webapp-service --type=NodePort --port=8080 --target-port=8080 --dry-run=client -o yaml > svc.yaml		## deployment must be present before exposing. and need to edit deployment to mention the nodeport, as we cannot set it directly through imp.command		### to generate a yaml file (svc.yaml) without creating a service

kubectl expose deployment my-deployment02 --name=mylbs --type=LoadBalancer --port=80 --target-port=80		## to expose deployment as loadbalancer service



kubectl get svc		### get the services details

kubectl describe svc kubernetes		### describes the default svc "kubernetes"s

kubectl get endpoints		## to check endpoints created by the service
kubectl get ep			## to check endpoints connected by the service

## kubectl run mybusybox01 --image=busybox -it --restart=Never --rm -- wget -O- http://<service-name>		## to test the connection of service within pods. Can use ip address as well



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					Imperative Vs Declarative
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~
	Imperative:-
~~~~~~~~~~~~~~~~~~
kubectl run --image=nginx nginx		## create objects

kubectl create deployment --image=nginx nginx

kubectl expose deploymet nginx --port 80

kubectl edit deployment nginx		## update Ojects

kubectl scale deployment nginx --replicas=5

kubectl set image deployment nginx nginx=nginx:1.18

kubectl create -f nginx.yaml

kubectl replace -f nginx.yaml		### first edit the yaml file and then execute the command

kubectl replace --force -f nginx.yaml

kubectl delete -f nginx.yaml

~~~~~~~~~~~~~~~~~~~
	Declarative:-
~~~~~~~~~~~~~~~~~~~
kubectl apply -f nginx.yaml		## create Objects

kubectl apply -f /path/to/config-files		### to create multiple objects at once. if multiple yaml file are present

kubectl apply -f nginx.yaml		## update Objects



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					Scheduling
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
kubectl -n kube-system get pods			### to check if the kube-sheduler pod is present ### sheduler pod must be present with other pods



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					Labels & Selectors
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
kubectl get node node01 --show-labels			### show all labels of node node01

kubectl get pods --show-labels			### show all labels of the existing pods

kubectl get pods -l env=dev			### to find pod with perticular label

kubectl get pods -l env=dev,bu=finance

kubectl get pods -l env=dev --no-headers | wc -l			### to count no of pods in environment "dev"

kubectl get pods --selector app=App1			## to get the pods with the help of selector



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					Taints and Toleration 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
kubectl taint nodes node-name key=value:taint-effect		### syntax; effect:-(NoSchedule | PreferNoSchedule | NoExecute)

kubectl taint node node-name key-		### untaint the node # - sign at end of key will untaint the node

kubectl taint nodes node1 key1=value1:NoSchedule		### to taint on node with key-value

kubectl taint nodes node1 app=blue:NoSchedule		### to taint on node with key-value

kubectl taint nodes controlplane node-role.kubernetes.io/master:NoSchedule		### need to try this command not sure, to taint controlplane with key only.

kubectl taint nodes controlplane node-role.kubernetes.io/master:NoSchedule-		## - sign at last removes taint on node



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					Node Selectors
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
kubectl label nodes <node-name> <label-key>=<label-value>			### syntax to label a node

kubectl label nodes node-1 size=Large			### label node-1 "size=Large"

kubectl get node node-1 --show-labels

kubectl label node <nodename> <labelname>-
kubectl label node node-1 size-



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					Node Affinity
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
kubectl label nodes node-1 color=blue		### label the node first, and inject(add) the nodeaffinity in the pod spec of pod-definition.yaml file



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					DaemonSets
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
kubectl create -f daemonset.yml			### file same as replicaset only difference is kind, kind: DaemonSets

kubectl get ds			### to check the daemonsets present in current namespace (default)

kubectl get daemonsets --all-namespaces			### to check daemonsets in all namespaces



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					Static Pods
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
docker ps		### to check static pods creation. because its indipendent from cluster.

ps -aux | grep kubelet		### kubelete is responsible to run static pods

ps -aux | grep kubelet | grep .yaml		### copy the path of --config=/..../config.yaml

cat /..../config.yaml | grep -i staticPodPath		### get the path of pod files location.

--
ps -aux | grep -i "\--config"		### contains .yaml file // search --config on kubelet.

cat /var/lib/kubelet/config.yaml | grep -i staticpod		### kubelet config file location; here the static pod definition file location is configured.

ls /etc/kubernetes/manifests		### to list the files of default static pod definitions present in manifest folder.


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					Multi Scheduler
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
cd /etc/kubernetes/manifests/		### to check the manifest files; kube-scheduler.yaml

cat /etc/kubernetes/manifest/kube-scheduler.yaml		### sheduclar file

kubectl get events



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					Logging and Monitoring 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~
	Monitoring:-
~~~~~~~~~~~~~~~~~~
git clone https://github.com/kubernetes-incubator/metrics-server.git			### clone files of metrics-server from git
kubectl create –f deploy/1.8+/			###creating a pod "metrics-server-" in kube-system for monitoring purpose; required pods/services gets created.

kubectl top node		### monitor performance metrics of node

kubectl top pod			### monitor performance metrics of pods

watch "kubectl top node"	### to watch it live performance 

~~~~~~~~~~~~~~~
	Logging:-
~~~~~~~~~~~~~~~
kubectl create -f event-simulator.yaml			### event stimulator for logs

kubectl logs -f event-simulator-pod

kubectl logs -f event-simulator-pod event-simulator			### specify name of teh container "event-simulator" if multiple containers are present in pod

kubectl logs webapp-1 | grep -i user5			### refined/consized output for pod "webapp-1"

kubectl logs webapp-2 -c			### to check no of container present in the pod "webapp-2"

kubectl logs webapp-2 -c simple-webapp			### check logs for container "simple-webapp" of pod "webapp-2" 



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					Application Lifecycle Management
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
kubectl rollout status deployment/myapp-deployment		### to check the status of roll out

kubectl rollout history deployment/myapp-deployment		### to check history

kubectl set image deployment/myapp-deployment nginx=nginx:1.9.1		### here the deployment.yaml file will not be changed, so different configuration will be there in current running pod and the file.

kubectl rollout undo deployment/myapp-deployment		### if update wont work, we can reverse the update.

kubectl describe pod ubuntu-sleeper		### check command option.

~~~~~~~~~~~~~~~~~~
	ConfigMaps:-
~~~~~~~~~~~~~~~~~~

kubectl create configmap app-configmap \
--from-literal=color=blue \
--from-literal=mode=prod

echo -e "key1=value1\nkey2=value2" > config.properties		### pass values to file

kubectl create cm configmap2 --from-file=config.properties	### create config maps with the help of file.

kubectl create configmap webapp-color --from-literal=APP_COLOR=darkblue		### imperetive method cm "webapp-color"

kubectl create -f config-map.yaml		### create config via file

kubectl get configmaps		### to get list config maps

kubectl get cm		### to get list of configMaps

kubectl get configmaps webapp-color -o yaml		### to get the yaml file of current running config "webapp-color"

Kubectl describe configmaps webapp-color		### cm "webapp-color"

kubectl edit configmap CONFIGMAP_NAME

kubectl explain pods --recursive | grep envFrom -A3		### to get the format to update yaml file.


~~~~~~~~~~~~~~~~
	Secretes:-
~~~~~~~~~~~~~~~~
~~~
Generic
~~~
kubectl create secret generic <secret-name> --from-literal=<key>=<value>		### imperative approach, to create secret directly from command; entering direct parameters

kubectl create secret generic app-secret \
--from-literal=DB_Host=mysql \
--from-literal=DB_User=root \
--from-literal=DB_Password=paswrd

kubectl create secret generic <secret-name> --from-file=<pathToFile>			### imperative approach using file

kubectl create secret gereric app-secret --from-file=app_secret.properties		### file "app_secret.properties"

kubectl create -f secret-data.yaml		### declarative approach, to create a secret from yaml file

kubectl get secrets		### to get list of secrets

kubectl describe secrets		### to describe newly created secret; without displaying value

kubectl describe secrets -o yaml		### shows the yaml file; with displaying values

kubectl edit secret SECRET_NAME		### to edit the secret

echo -n 'mysql' | base64		### encoding value; to convert normal text "mysql" to encoded text "bX1zcWw="; to save encoded text in secret file instead of normal plain text.

echo -n 'bx1zcWw=' | base64 --decode		### decoding; to convert encoded text 'bx1zcWw=' to normal plain text 'mysql'

~~~
Docker-registry
~~~
kubectl create secret docker-registry regcred \
--docker-server=<your-registry-server> \
--docker-username=<your-name> \
--docker-password=<your-pword> \
--docker-email=<your-email>




~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					Cluster Maintenance
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

kubeadm token create --print-join-command		### print the link used to join the node to cluster.

~~~~~~~~~~~~~~~~~~~~
	Os Upgrades
~~~~~~~~~~~~~~~~~~~~
kubectl conrdon node-2		### it simply marks the node as "unschedulable" and do not terminates the existing pods; it makes sure the new pods are not created on it.

kubectl drain node-1		### existing pods are terminated from the "node-1" and recreated on another node; and "node-1" is marked as cordan and unschedulable.

kubectl uncordon node-1		### node-1 marked as uncordan to "schedule" pods.

kubectl drain node01 --ignore-daemonsets		### We cannot delete/drain DaemonSet-managed pods; so we ingnored it.


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	Kubernetes Software Versions:-
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
kubeadm version


~~~~~~~~~~~~~~~~~~~~~~~
	Cluster upgrade:-
~~~~~~~~~~~~~~~~~~~~~~~
kubectl cluster-info

kubeadm version		### to check the current version

kubectl version --short		### to check the version in short

kubeadm upgrade plan		### to check upgrade available

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~
	Upgrade master node:-
~~~~~~~~~~~~~~~~~~~~~~~~~~~
kubectl drain controlplane --ignore-daemonsets

apt install kubeadm=1.18.0-00
kubeadm upgrade apply v1.18.0

apt install kubelet=1.18.0-00
kubectl uncordon controlplane


~~~~~~~~~~~~~~~~~~~~~~~~~~~
	Upgrade worker node:-
~~~~~~~~~~~~~~~~~~~~~~~~~~~
kubectl drain node01		## from controlplane terminal.

ssh node01
apt install kubeadm=1.18.0-00
kubeadm upgrade node
apt install kubelet=1.18.0-00
exit

kubectl uncordon node01		### from controlplane terminal
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~
	Backup and restore:-
~~~~~~~~~~~~~~~~~~~~~~~~~~
kubectl get all --all-namespaces -o yaml > all-deploy-services.yaml
~~~~~~~~~~~~~~~~~~~~~~~~~
 
# ETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 \
--cacert=/etc/kubernetes/pki/etcd/ca.crt \
--cert=/etc/kubernetes/pki/etcd/server.crt \
--key=/etc/kubernetes/pki/etcd/server.key \
snapshot save /opt/snapshot-pre-boot.db 		### ### remember to specify --endpoints=" ",--cacert,--cert,--key  ; if running cmd on etcd which is on same master then no need apply endpoints. ##snapshotname: snapshot01.db; it is saved in pwd; specify path if required.
  
  $ ls		### snapshot.db ; files in pwd		### Backup using builtin snapshot utility
  $ ETCDCTL_API=3 etcdctl snapshot status snapshot01.db		### check status

  $ service kube-apiserver stop		###  stop kube-apiserver
  $ ETCDCTL_API=3 etcdctl snapshot restore snapshot01.db --data-dir /var/lib/etcd-from-backup		###* to restore ETCD cluster;	
 
  $ cd /etc/kubernetes/manifests/		 #
  $ vi etcd.yaml 	### volumes >hostPath >path:/varlib/etcd-from-backup (its mandatory)
  $ systemctl daemon-reload
  $ service etcd restart
  $ service kube-apiserver start


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
						Security
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

openssl gerrsa -out my-bank.key 1024			### user generate the key
openssl rsa -in mybank.key -pubout > mybank.pem		### user generate the CertificateSignRequest to send to admin

opensll req -new -key my-bank.key -out my-bank.scr -subj "/C=US/ST-CA/0=MyOrg, Inc./CN=my-bank.com"		### to generate a certificateSignRequest


cat /etc/systemd/system/kube-apiserver.service			### Deployed Kubernetes from Scratch - the hard way


cat /etc/kubernetes/manifests/kube-apiserver.yaml		### Deployed Kubernetes via kubeadm
openssl x509 -in /etc/kubernetes/pki/apiserver.crt -txt -noout		### to open and check the certificate details.


journalctl -u etcd.service -l			### if from scratch; check logs with the cmd

kubectl logs etcd-master			### if from kubeadm; logs followed by pod name (kube-system)

dcoker ps -a			### if not found via kubernetes; check one level down from docker, get the container id.

docker logs 87fc		### check the logs of 87fc cont id.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	CertificatesSignRequest:-
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
openssl genrsa -out jane.key 2048		### user generates the key

openssl req -new -key jane.key -subj "/CN=jane" -out jane.csr		### user then create certificateSignRequest with the name on it and sends to admin


cat myuser.csr | base64 | tr -d "\n"		### convert value to base64 to use under request feild of yaml file( CSR object)

### administrator takes a key and generates certificateSignRequest object (like other kubernetes object) with a manifest file.



kubectl get csr		#### Get list of CSRs

kubectl certificate approve mysuser		### approve the CSR

kubectl get csr/myuser -o yaml		### Retrieve the certificate from the CSR; and manualy export from base64 ; select from certificate:   ;or else follow below cmd.

kubectl get csr myuser -o jsonpath='{.status.certificate}'| base64 -d > myuser.crt		### The certificate value is in Base64-encoded format under status.certificate. Export the issued certificate from the CertificateSigningRequest.


~~~~~~~~~~~~~~~~~~
	kubeconfig:-
~~~~~~~~~~~~~~~~~~
kubectl config view   ### to check the no of clusters present.
kubectl config view --kubeconfig=my-custom-config  ### to check context
kubectl config use-context prod-user@production   ### to change context to production.
kubectl config  -h   ### list of supported commads


~~~~~~~~~~~~~~~~~~
	API Groups:-
~~~~~~~~~~~~~~~~~~
kubectl api-resources

kubectl api-resources --namespaced=true   	### to check the resources which are namespaced scoped
kubectl api-resources --namespaced=false  	### to chekc resources which are cluster scoped

~~~~~~~~~~~~
	RBAC:-
~~~~~~~~~~~~
kubectl --namespace=development create role developer --resource=pods --verb=create,list,get,update,delete
	
kubectl get roles
kubectl get rolebindings
kubectl describe role developer
kubectl describe rolebinding devuser-developer-biniding

kubectl auth can-i create deployments   ### yes

kubectl auth can-i delete nodes  ### no

kubectl auth can-i create deployments --as dev-user   ### no.  # to check access of user

kubectl auth can-i create pods --as dev-user --namespace test   ### to test access in namespace for user "dev-user"

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	Cluster roles & Role bindings:-
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

kubectl --namespace=development create rolebinding developer-role-binding --role=developer --user=john

kubectl get clusterroles		### to check/get cluster roles present

kubectl get clusterrolebindings		### to check/get cluster rolebindings


~~~~~~~~~~~~~~~~~
Network policy
~~~~~~~~~~~~~~~~~

kubectl get netpol   ### to get the network policy

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					Volumes
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

kubectl get persistentvolume

kubectl get persistentvolumeclaim

~~~~~~~~
Storage class
~~~~~~~~~~

kubectl get sc		## to get the storage class


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					Networking
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Note:- some commands are valid till system restart. for perme

ip link		### list and modify interfaces of the host

ip addr		## to check ip addresses assigned to those interfaces

ip addr add 192.168.1.10/24 dev ehth0		### to set the ip address to host machine

ip route		### to check the entries in routing table.

route			### to check entries in routing table

ip route add 192.168.2.0/24 via 192.168.1.1

ip route add default via 192.168.2.1

cat /proc/sys/net/ipv4/ip_forward		### 0 ### systems-A,B,C. A connected to B at eth0. B connect to C at eth1. system B with two network cards eth0 and eth1. etho0 does not send packets to eth1 if the value is 0.

echo 1 > /proc/sys/net/ipv4/ip_forward		### enable ip forwarding on host.

cat /proc/sys/net/ipv4/ip_forward		### 1 ### command to check ip forwarding is enabled on the host

~~~~~~~~~~~
	DNS:-
~~~~~~~~~~~

cat >> /etc/hosts		### add entry for DNS. this is also known as Name Resolution.

note: if one of the hosts ip changes, then we need to configure it in all files in different systesm

cat /etc/resolve.conf		### dns server ip maintained at this location of the host.

record types
A		for ipv4
AAAA		for ipv6
CNAME		for name change records.

nslookup		### it queries DNS server not local
dig			### 

Network NS

ip netns add red	### 

ls /opt/cni/bin  ### cni plugins list
cat /etc/cni/net.d/		### to check the networking solution used by cluster

kubectl -n kube-system logs weave-net-h2x9w -c weave	### to check teh logs of network plugins for ip address range.

kubectl logs kube-proxy-ft6n7 -n kube-system


cat /etc/coredns/Corefile		### main file for coredns


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					Troubleshooting
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	1) check connectivity
$ curl http://web-service-ip:node-port
$ curl http://172.16.10.10:8181

	2) check if pod is in running state
$ kubectl get pod

	3) check logs 
kubectl logs web -f
kubectl logs web -f --previous

	4) check endpoints in namespace
kubectl -n gama get ep

	5) check environment variables.


~~~~~~~~~~~~~~~~~~~~
Worker node failure :-
~~~~~~~~~~~~~~~~~~~~
kubectl get nodes			## check if its ready
kubectl describe node worker-1		## check if the status is true:-not healthy due to symtoms, false: healty

top
df -h 

serive kubelet status
sudo journalctl -u kubelet

openssl x509 -in /var/lib/kubelet/worker-1.crt -text

	1) check if the process for kubelet is running.
$ ps -ef | grep -i kubelet		
$ systemctl status kubelet.service
$ systemctl restart kubelet

	2) certificate issue
$ sudo journalctl -u kubelet
$ cd /etc/systemd/system/kubelet.service.d/
$ cat 10-kubeadm.conf

$ cat /../kubelet.yaml
	- check the certificate 
	- correct the certificate url

$ systemctl daemon reload
$ systemctl restart kubelet

3)
$ cat 10-kubeadm.conf
	--kubeconfig=/etc/kubernetes/kubelet.conf

$ vi /etc/kubernetes/kubelet.conf
	6553 to 6443

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					ResourceQuota
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

$ kubectl create quota -h

$ kubectl run mypod --image=nginx --restart=Never \
--requests='cpu=250m,memory=64Mi' \
--limits='cpu=520m,memory=128'

$ kubectl create quota myrq --hard=cpu=1,memory=1G,pods=2



